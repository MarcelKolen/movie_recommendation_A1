{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hey Luit, hier alvast een opzet van de opdracht. Ik zal per blokje kort even aangeven of het boeiend voor jou is.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is **niet** belangrijk voor jouw onderdelen, dit is alleen hier om het inladen van bestanden te fixen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_add(format_list, input_data, target_data):\n",
    "    ### Constructs a dictionary using input_data and \n",
    "    ### the format_list as the dictionary format and \n",
    "    ### appends the dictionary to the target data.\n",
    "    \n",
    "    appender_dict = {}\n",
    "    \n",
    "    for count, item in enumerate(format_list):\n",
    "        try:\n",
    "            appender_dict.update({item: input_data[count]})\n",
    "        except IndexError:\n",
    "            appender_dict.update({item: None})\n",
    "            \n",
    "    target_data.append(appender_dict)\n",
    "\n",
    "def build_file(format_list, file_path, delimiter):\n",
    "    ### Reads a file and converts the delimiter separated data \n",
    "    ### in the file, based on the format provided by format_list, \n",
    "    ### into a dictionary list.\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    with open(file_path) as file:\n",
    "        print(f\"Unpacking: '{file_path}'\")\n",
    "    \n",
    "        for line in file:\n",
    "            stripped_line = line.strip().split(delimiter)\n",
    "            format_add(format_list, stripped_line, new_list)\n",
    "        \n",
    "    print(\"Unpacked succesfully\")\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier staan de drie belangrijke datasets.\n",
    "\n",
    "```user_data``` is een lijst van dictionaries waar elke dict een regel is uit de oorspronkelijke data bestanden. De keys zie je in de lijst van ```build_file()```. ```movie_data```en ```rating_data``` hebben het zelfde princiepe.\n",
    "\n",
    "Als je ```user_data[0]``` gebruikt, krijg je dus een hele regel. Let op, UIDs en ```[id]``` zijn mogelijk niet 1 op 1! (zie ```find_on_key_and_value``` voor makkelijker zoeken naar gebruikers/movies/ratings/andere dingen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking: './ml-1m/users.dat'\n",
      "Unpacked succesfully\n",
      "Unpacking: './ml-1m/movies.dat'\n",
      "Unpacked succesfully\n",
      "Unpacking: './ml-1m/ratings.dat'\n",
      "Unpacked succesfully\n"
     ]
    }
   ],
   "source": [
    "file_path_users = \"./ml-1m/users.dat\"\n",
    "file_path_movies = \"./ml-1m/movies.dat\"\n",
    "file_path_ratings = \"./ml-1m/ratings.dat\"\n",
    "\n",
    "user_data = build_file(\n",
    "    [\"uid\", \"gender\", \"age\", \"occupation\", \"zip-code\"],\n",
    "    file_path_users,\n",
    "    \"::\"\n",
    ")\n",
    "\n",
    "movie_data = build_file(\n",
    "    [\"mid\", \"title\", \"genre\"],\n",
    "    file_path_movies,\n",
    "    \"::\"\n",
    ")\n",
    "\n",
    "rating_data = build_file(\n",
    "    [\"uid\", \"mid\", \"rating\", \"timestamp\"],\n",
    "    file_path_ratings,\n",
    "    \"::\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik dit om een entry te zoeken gebaseerd op een key (zoals *uid*, *gender*, *title*) en de verwachtte waarde. **Let op** dit retourneerd een lijst (kunnen dus meerdere entries zijn), maar als je maar 1 ding zoekt doe je gewoon: ```find_on_key_and_value(blah, blah, blah)[0]``` of ```find_on_key_and_value(blah, blah, blah)[:1]``` (als er niets gevonden is krijg je een lege lijst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_on_key_and_value(target_data, key, value):\n",
    "    ### Filter the data based on a key-value combination in the list of dictionaries.\n",
    "    return list(filter(lambda obj : obj[key] == value, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier een algemeen gemiddelde, niet zo spannend denk ik, maar misschien nodig bij de twee grotere methodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier moet je vooral niet kijken naar wat de code is, want comprehension is lekker niet zo leesbaar, maar dit zoekt alle gemiddelden voor een bepaalde ```target_mean``` gebaseerd op een ```target_key```.\n",
    "\n",
    "Dus: ```bind_mean(rating_data, user_data, \"uid\", \"rating\", all_rating_mean)``` zoekt voor alle gebruikers (*uid*) de gemiddelde rating die die gebruiker heeft gegeven en maakt vervolgens een dictionary met daarin de gemiddelde van die gebruikers gekoppeld aan de uid van die gebruiker.\n",
    "\n",
    "Oh ja, **let op**, de dataset is nogal groot, dus let er op dat dit even kan duren voordat het klaar is (5 minuten ofzo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, isnan\n",
    "\n",
    "def bind_mean(bind_data_source, bind_data_target, target_key, target_mean, default=None):\n",
    "    ### Creates a dictionary of target_keys with their respective means. \n",
    "    ### If the target key does not exist in the source_data, then a default value will be set.\n",
    "    return {l_obj[target_key]: x if not isnan(x := mean([int(item[target_mean]) for item in filter(lambda _r : _r[target_key] == l_obj[target_key], bind_data_source)])) else default for l_obj in bind_data_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def construct_M_array(row_size, column_size, data, make_nan=True):\n",
    "    M_array = np.zeros((row_size, column_size))\n",
    "\n",
    "    for item in data:\n",
    "        itv = list(item.values())\n",
    "        M_array[int(itv[0]) - 1, int(itv[1]) - 1] = float(itv[2])\n",
    "\n",
    "    if make_nan:\n",
    "        M_array = np.where(M_array == 0., np.NaN, M_array)\n",
    "        \n",
    "    return M_array\n",
    "\n",
    "def get_row_col_mean(data):\n",
    "    return np.nanmean(data, axis=1), np.nanmean(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def RSME_two_arrays(arr_1, arr_2):\n",
    "    return np.sqrt(np.nanmean(((arr_1 - arr_2) ** 2)))\n",
    "\n",
    "def MAE_two_arrays(arr_1, arr_2):\n",
    "    return np.nanmean(np.absolute(arr_1 - arr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def replace_nans(arr):\n",
    "    copy_arr = np.copy(arr)\n",
    "    \n",
    "    inds = np.where(np.isnan(copy_arr))\n",
    "\n",
    "    copy_arr[inds] = np.take(np.nanmean(copy_arr, axis=0), inds[1])\n",
    "    \n",
    "    return copy_arr\n",
    "\n",
    "def preprocess_array(arr):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "        ret_arr = np.copy(arr)\n",
    "        \n",
    "        row_mean = np.zeros((arr.shape[0], ))\n",
    "        column_mean = np.zeros((arr.shape[1], ))\n",
    "        \n",
    "        for row in range(ret_arr.shape[0]):\n",
    "            row_mean[row] = np.nanmean(ret_arr[row])\n",
    "            ret_arr[row] = ret_arr[row] - row_mean[row]\n",
    "        for column in range(ret_arr.shape[1]):\n",
    "            column_mean[column] = np.nanmean(ret_arr[:,column])\n",
    "            ret_arr[:,column] = ret_arr[:,column] - column_mean[column]\n",
    "        return ret_arr, row_mean, column_mean\n",
    "    \n",
    "def unprocess_array(arr, row_mean, column_mean):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "        ret_arr = np.copy(arr)\n",
    "\n",
    "        for column in range(ret_arr.shape[1]):\n",
    "            ret_arr[:,column] = ret_arr[:,column] + column_mean[column]\n",
    "        for row in range(arr.shape[0]):\n",
    "            ret_arr[row] = arr[row] + row_mean[row]\n",
    "        return ret_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in een trainings- en testset\n",
    "\n",
    "\n",
    "#Ik neem aan alleen de rating_data? dit zouden ze ook alle drie kunnen zijn maar logischerwijs heb je niks aan de rest van de data zonder rating dus dacht ik dat dit voldoende zou zijn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Rating_train, Rating_test = train_test_split(rating_data, test_size=0.2, random_state=42)\n",
    "\n",
    "training_array = construct_M_array(int(user_data[-1]['uid']), int(movie_data[-1]['mid']), Rating_train)\n",
    "\n",
    "testing_array = construct_M_array(int(user_data[-1]['uid']), int(movie_data[-1]['mid']), Rating_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier doen  we wat leuke testjes op de trainingsset\n",
    "\n",
    "#Deze had jij al staan, ik heb enkel de rating_data naar rating_train gebracht omdat dit de enige data is waar nu naar gekeken mag worden en R_global is hetzelfde als all_rating_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-658-c74362966e6a>:16: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(data, axis=1), np.nanmean(data, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#the global average rating \n",
    "R_global = np.nanmean(training_array)\n",
    "\n",
    "#the average rating per user & item \n",
    "R_user, R_item = get_row_col_mean(training_array)\n",
    "\n",
    "R_user = np.nan_to_num(R_user, nan=np.nanmean(R_user))\n",
    "\n",
    "R_item = np.nan_to_num(R_item, nan=np.nanmean(R_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(R_item):\n",
    "    if np.isnan(item):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive approaches\n",
    "\n",
    "#Hier is regressie nodig en dus de kritieke code. Om LR.fit uit te voeren hebben we arrays nodig met een X en Y met de volgende voorwaarde:\n",
    "    - X: X{array-like, sparse matrix} of shape (n_samples, n_features), // Training data.\n",
    "    - Y: array-like of shape (n_samples,) or (n_samples, n_targets), // Target values. Will be cast to X’s dtype if necessary.\n",
    "\n",
    "Hierbij mijn vraag of LR.score gebruikt moet worden of LR.predict en wat precies de waardes zijn die in LR.fit moeten zitten. Dit is op dit moment in ieder geval nog **niet helemaal correct** !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_item.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "#an “optimal” linear combination of the two averages (per user and per item) without gamma\n",
    "LR_1 = LinearRegression()\n",
    "LR_2 = LinearRegression()\n",
    "\n",
    "user_ids_array = np.arange(1, int(user_data[-1]['uid']) + 1, 1)\n",
    "\n",
    "print \n",
    "\n",
    "LR_1.fit(user_ids_array.reshape(-1,1), R_user)\n",
    "alpha = LR_1.coef_\n",
    "\n",
    "item_ids_array = np.arange(1, int(movie_data[-1]['mid']) + 1, 1)\n",
    "\n",
    "LR_2.fit(item_ids_array.reshape(-1,1), R_item)\n",
    "beta = LR_2.coef_\n",
    "\n",
    "gamma = (LR_1.intercept_ + LR_2.intercept_) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berekenen van de resultaten van de training, de RMSE!\n",
    "\n",
    "#Dit klopt buiten het feit dat alpha en beta nog niet op orde zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root mean squared error\n",
    "RMSE_global = 0\n",
    "RMSE_item = 0\n",
    "RMSE_user = 0\n",
    "RMSE_user_item = 0\n",
    "RMSE_user_item_gamma = 0\n",
    "\n",
    "for rating in Rating_test:\n",
    "    RMSE_global += (int(rating['rating']) - int(R_global))**2    \n",
    "    \n",
    "    try:\n",
    "        RMSE_item += (int(rating['rating']) - R_item[int(rating['mid']) - 1])**2\n",
    "    except:\n",
    "        RMSE_item += (int(rating['rating']) - int(R_global))**2\n",
    "        \n",
    "    try:\n",
    "        RMSE_user += (int(rating['rating']) - R_user[int(rating['uid'])  - 1])**2\n",
    "    except:\n",
    "        RMSE_user += (int(rating['rating']) - int(R_global))**2\n",
    "    \n",
    "    try:\n",
    "        RMSE_user_item += (int(rating['rating']) - int((alpha*R_user[int(rating['uid'])  - 1] + beta*R_item[int(rating['mid'])  - 1])))**2\n",
    "    except:\n",
    "        RMSE_user_item += (int(rating['rating']) - int(R_global))**2\n",
    "    \n",
    "    try:\n",
    "        RMSE_user_item_gamma += (int(rating['rating']) - int((alpha*R_user[int(rating['uid'])  - 1] + beta*R_item[int(rating['mid'])  - 1]) + gamma))**2\n",
    "    except:\n",
    "        RMSE_user_item_gamma += (int(rating['rating']) - int(R_global))**2\n",
    "            \n",
    "RMSE_global = np.sqrt(RMSE_global/len(Rating_test))\n",
    "RMSE_item = np.sqrt(RMSE_item/len(Rating_test))\n",
    "RMSE_user = np.sqrt(RMSE_user/len(Rating_test))\n",
    "RMSE_user_item = np.sqrt(RMSE_user_item/len(Rating_test))\n",
    "RMSE_user_item_gamma = np.sqrt(RMSE_user_item_gamma/len(Rating_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berekenen van de resultaten van de training, de MAE!\n",
    "\n",
    "#Dit klopt buiten het feit dat alpha en beta nog niet op orde zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean absolute error\n",
    "MAE_global = 0\n",
    "MAE_item = 0\n",
    "MAE_user = 0\n",
    "MAE_user_item = 0\n",
    "MAE_user_item_gamma = 0\n",
    "\n",
    "for rating in Rating_test:\n",
    "    MAE_global += abs(int(rating['rating']) - int(R_global))   \n",
    "    \n",
    "    try:\n",
    "        MAE_item += abs(int(rating['rating']) - R_item[int(rating['mid']) - 1])\n",
    "    except:\n",
    "        MAE_item += abs(int(rating['rating']) - int(R_global))\n",
    "        \n",
    "    try:\n",
    "        MAE_user += abs(int(rating['rating']) - R_user[int(rating['uid']) - 1])\n",
    "    except:\n",
    "        MAE_user += abs(int(rating['rating']) - int(R_global))\n",
    "    \n",
    "    try:\n",
    "        MAE_user_item += abs(int(rating['rating']) - int((alpha*R_user[int(rating['uid']) - 1] + beta*R_item[str(rating['mid']) - 1])))\n",
    "    except:\n",
    "        MAE_user_item += abs(int(rating['rating']) - int(R_global))\n",
    "    \n",
    "    try:\n",
    "        MAE_user_item_gamma += abs(int(rating['rating']) - int((alpha*R_user[int(rating['uid']) - 1] + beta*R_item[int(rating['mid']) - 1]) + gamma))\n",
    "    except:\n",
    "        MAE_user_item_gamma += abs(int(rating['rating']) - int(R_global))\n",
    "\n",
    "MAE_global = MAE_global/len(Rating_test)\n",
    "MAE_item = MAE_item/len(Rating_test)\n",
    "MAE_user = MAE_user/len(Rating_test)\n",
    "MAE_user_item = MAE_user_item/len(Rating_test)\n",
    "MAE_user_item_gamma = MAE_user_item_gamma/len(Rating_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printen van de resultaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2621491455854978\n",
      "0.9823658303441268\n",
      "1.039434029917006\n",
      "3.753347386069386\n",
      "1.2621491455854978\n",
      "\n",
      "\n",
      "1.0239899621079573\n",
      "0.7851682906441758\n",
      "0.8329949719978602\n",
      "1.0239899621079573\n",
      "1.0239899621079573\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_global)\n",
    "print(RMSE_item)\n",
    "print(RMSE_user)\n",
    "print(RMSE_user_item)\n",
    "print(RMSE_user_item_gamma)\n",
    "print(\"\\n\")\n",
    "print(MAE_global)\n",
    "print(MAE_item)\n",
    "print(MAE_user)\n",
    "print(MAE_user_item)\n",
    "print(MAE_user_item_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization section\n",
    "\n",
    "Een standaard predictfunctie die gebruik maakt van de R_item en de R_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict de data aan de hand van gemiddelde per user en gemiddelde per film\n",
    "def predictRating(movie, user):\n",
    "    return (R_item[int(movie)] + R_user[int(user)])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De trainingsfunctie die mbv een errorrate een learningrate en een K. Deze trainingsfunctie beinvloed de userValue en de movieValue die essentieel zijn om de nieuwe ratings te voorspellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''''''\n",
    "Where:\n",
    " *  real *userValue = userFeature[featureBeingTrained];\n",
    " *  real *movieValue = movieFeature[featureBeingTrained];\n",
    " *  real  lrate = 0.001;\n",
    "'''''''''\n",
    "#Train de data mbv een errorrate en de standaard predictRating functie\n",
    "def train(user, movie, rating):\n",
    "    lrate = 0.001\n",
    "    K = 0.02\n",
    "    \n",
    "    err = lrate * (rating - predictRating(movie, user))\n",
    "    \n",
    "    uv = userValue[user];    \n",
    "    userValue[user] += lrate * (err * movieValue[movie] - K * userValue[user]);\n",
    "    movieValue[movie] += lrate * (err * uv - K * movieValue[movie]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De functies die het trainen en voorspellen mogelijk maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.46699395 3.53900487 3.54999447 ... 3.57550261 3.57622573 3.55666275]\n",
      " [3.46211469 3.53412561 3.54511522 ... 3.57062336 3.57134648 3.55178349]\n",
      " [3.46698427 3.53899519 3.5499848  ... 3.57549294 3.57621606 3.55665307]\n",
      " ...\n",
      " [3.46876521 3.54077613 3.55176574 ... 3.57727388 3.577997   3.55843401]\n",
      " [3.46232109 3.53433201 3.54532162 ... 3.57082976 3.57155288 3.55198989]\n",
      " [3.45032969 3.52234061 3.53333021 ... 3.55883835 3.55956147 3.53999849]]\n"
     ]
    }
   ],
   "source": [
    "#ratingsMatrix[user][movie] = sum (userFeature[f][user] * movieFeature[f][movie]) for f from 1 to 40\n",
    "\n",
    "#verticaal user_data en horizontaal movie_data\n",
    "ratingsMatrix = np.full((int(user_data[-1]['uid']), int(movie_data[-1]['mid'])), 0.01)\n",
    "\n",
    "#initieer de userValue en de movieValue array\n",
    "userValue = np.full((int(user_data[-1]['uid']), ), R_global)\n",
    "movieValue = np.full((int(movie_data[-1]['mid']), ), R_global)\n",
    "\n",
    "#Train de data op de trainingsset\n",
    "for rating in Rating_train: \n",
    "    train(int(rating['uid']) - 1, int(rating['mid']) - 1, int(rating['rating']))\n",
    "\n",
    "#Vul de rest van de waardes in op basis van de trainingsset\n",
    "for user in user_data:\n",
    "    for movie in movie_data:\n",
    "        ratingsMatrix[int(user['uid']) - 1, int(movie['mid']) - 1] = (userValue[int(user['uid']) - 1] + movieValue[int(movie['mid']) - 1])/2\n",
    "\n",
    "#Print het eindresultaat\n",
    "print(ratingsMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1291770882634757\n",
      "0.9517791729018711\n"
     ]
    }
   ],
   "source": [
    "print(RSME_two_arrays(ratingsMatrix, testing_array))\n",
    "print(MAE_two_arrays(ratingsMatrix, testing_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UV Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_U_cell(r, s, dim, U_matrix, V_matrix, M_matrix):\n",
    "    x_above = 0\n",
    "    \n",
    "    for j in range(M_matrix.shape[1]):\n",
    "        M_val = M_matrix[r,j]\n",
    "        \n",
    "        if np.isnan(M_val):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        U_el_V_el_sum = 0\n",
    "        \n",
    "        for k in range(dim):\n",
    "            if k == s:\n",
    "                continue\n",
    "            U_el_V_el_sum += U_matrix[r,k] * V_matrix[k,j]\n",
    "            \n",
    "        x_above += V_matrix[s,j] * (M_val - U_el_V_el_sum)\n",
    "        \n",
    "    x_under = 0\n",
    "    \n",
    "    for j in range(M_matrix.shape[1]):\n",
    "        if np.isnan(M_matrix[r,j]):\n",
    "            continue\n",
    "            \n",
    "        x_under += V_matrix[s, j] ** 2\n",
    "    \n",
    "    return x_above / x_under if x_under != 0. else y_above / 1e10\n",
    "\n",
    "def optimize_V_cell(r, s, dim, U_matrix, V_matrix, M_matrix):\n",
    "    y_above = 0\n",
    "    \n",
    "    for i in range(M_matrix.shape[0]):\n",
    "        M_val = M_matrix[i,s]\n",
    "        \n",
    "        if np.isnan(M_val):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        U_el_V_el_sum = 0\n",
    "        \n",
    "        for k in range(dim):\n",
    "            if k == r:\n",
    "                continue\n",
    "            U_el_V_el_sum += U_matrix[i,k] * V_matrix[k,s]\n",
    "            \n",
    "        y_above += U_matrix[i,r] * (M_val - U_el_V_el_sum)\n",
    "        \n",
    "    y_under = 0\n",
    "    \n",
    "    for i in range(M_matrix.shape[1]):\n",
    "        if np.isnan(M_matrix[i,s]):\n",
    "            continue\n",
    "            \n",
    "        y_under += U_matrix[i, r] ** 2\n",
    "    \n",
    "    return y_above / y_under if y_under != 0. else y_above / 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_opti_round_robin(U_d_matrix, V_d_matrix, M_matrix, dimensions):\n",
    "    r_U, c_U = 0, 0\n",
    "    r_V, c_V = 0, 0\n",
    "    \n",
    "    run = True\n",
    "    \n",
    "    while run:\n",
    "        run = False\n",
    "        if r_U < U_d_matrix.shape[0] and c_U < U_d_matrix.shape[1]:\n",
    "            U_d_matrix[r_U, c_U] = optimize_U_cell(r_U, c_U, dimensions, U_d_matrix, V_d_matrix, M_matrix)\n",
    "            run = True\n",
    "            \n",
    "            c_U += 1\n",
    "\n",
    "            if c_U >= U_d_matrix.shape[1]:\n",
    "                r_U += 1\n",
    "                c_U = 0\n",
    "            \n",
    "        if r_V < V_d_matrix.shape[0] and c_V < V_d_matrix.shape[1]:\n",
    "            V_d_matrix[r_V, c_V] = optimize_V_cell(r_V, c_V, dimensions, U_d_matrix, V_d_matrix, M_matrix)\n",
    "            run = True\n",
    "            \n",
    "            c_V += 1\n",
    "\n",
    "            if c_U >= V_d_matrix.shape[1]:\n",
    "                r_V += 1\n",
    "                c_V = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_UV_array(U_d_matrix, V_d_matrix, M_array, dimensions, reference_RSME, max_rounds=1000, improvement_threshold=1.0e-10):\n",
    "    difference = None\n",
    "\n",
    "    for i in range(1000):\n",
    "        print(f\"opti-cycle {i}\")\n",
    "        run_opti_round_robin(U_d_matrix, V_d_matrix, M_array, dimensions)\n",
    "\n",
    "        result = RSME_two_arrays(M_array, np.matmul(U_d_matrix, V_d_matrix))\n",
    "        \n",
    "        improvement = reference_RSME - result if difference is None else difference - result\n",
    "        print(f\"RSME result round {i}: {result}, this constitutes an improvement of: {reference_RSME - result} and a difference of {improvement}\")\n",
    "        \n",
    "        if improvement < improvement_threshold:\n",
    "            print(\"Improvement threshold reached, optimization stopping\")\n",
    "            return\n",
    "        \n",
    "        difference = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-794-c1215def58d5>:9: RuntimeWarning: Mean of empty slice\n",
      "  copy_arr[inds] = np.take(np.nanmean(copy_arr, axis=0), inds[1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# users_movies_array = np.zeros((int(user_data[-1]['uid']), int(movie_data[-1]['mid'])))\n",
    "\n",
    "# for rating in rating_data:\n",
    "#     rv = list(rating.values())\n",
    "#     users_movies_array[int(rv[0]) - 1, int(rv[1]) - 1] = float(rv[2])\n",
    "    \n",
    "# users_movies_array = np.where(users_movies_array == 0., np.NaN, users_movies_array)\n",
    "\n",
    "users_movies_array_no_nans = replace_nans(training_array)\n",
    "\n",
    "users_movies_array_pp, row_mean, column_mean = preprocess_array(users_movies_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_users_movies_array = np.nanmean(users_movies_array_pp)\n",
    "dimensions = 5\n",
    "\n",
    "start_value = np.sqrt(mean_users_movies_array/dimensions)\n",
    "\n",
    "users_d_matrix = np.full((users_movies_array.shape[0], dimensions), start_value)\n",
    "movies_d_matrix = np.full((dimensions, users_movies_array.shape[1]), start_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_line_opti: 1.028448620929304\n",
      "opti-cycle 0\n",
      "RSME result round 0: 0.8975893580392296, this constitutes an improvement of: 0.13085926289007443 and a difference of 0.13085926289007443\n",
      "opti-cycle 1\n",
      "RSME result round 1: 0.8977229743863595, this constitutes an improvement of: 0.1307256465429445 and a difference of -0.00013361634712993897\n",
      "Improvement threshold reached, optimization stopping\n",
      "Final result: 1.043038206984398\n"
     ]
    }
   ],
   "source": [
    "base_line = RSME_two_arrays(users_movies_array, unprocess_array(np.matmul(users_d_matrix, movies_d_matrix), row_mean, column_mean))\n",
    "print(f\"base_line_opti: {base_line}\")\n",
    "\n",
    "optimize_UV_array(users_d_matrix, movies_d_matrix, users_movies_array_pp, dimensions, base_line)\n",
    "\n",
    "prediction_UV_array = unprocess_array(np.matmul(users_d_matrix, movies_d_matrix), row_mean, column_mean)\n",
    "\n",
    "print(f\"Final result: {RSME_two_arrays(testing_array, prediction_UV_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.043038206984398\n",
      "0.839151553056242\n"
     ]
    }
   ],
   "source": [
    "print(RSME_two_arrays(prediction_UV_array, testing_array))\n",
    "print(MAE_two_arrays(prediction_UV_array, testing_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
