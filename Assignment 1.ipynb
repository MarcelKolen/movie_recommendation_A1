{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## JuPyter Notebook - Verschuur L. 1811053, Kolenbrander M. 1653415\n",
    "This JuPyter Notebook contains the three different implementations for estimating movie ratings. The implementations are as described in **assignment 1** of the course **Advances in Datamining 2021/2022**.\n",
    "\n",
    "In this assignment we are tasked with implementing the three different approaches and then testing their accuracy. To measure the accuracy, we employ the *Root Mean Squared Error (RMSE)* and *Mean Absolute Error (MAE)* metrics.\n",
    "\n",
    "In order to increase the reliability of our results, we use the *5 fold cross validation* technique. For every fold we run, we capture the RMSE and MAE values and add them to an average. The results we present are therefor the average RMSE and MAE values over the 5 folds.\n",
    "\n",
    "#### The methods\n",
    "The three different methods we used are as follows:\n",
    "- `The Naive approaches`\n",
    "    - `Predicted rating is the global average`\n",
    "    - `Predicted rating is the user average`\n",
    "    - `Predicted rating is the item average`\n",
    "    - `Predicted rating is a linear regression result`\n",
    "    - `Predicted rating is a linear regression result with a gamma value`\n",
    "- `UV Matrix Decomposition`\n",
    "- `Matrix Factorisation`\n",
    "\n",
    "In this notebook, we have separated the relevant methods/functions according to their approach, so: all UV matrix decomposition methods are together, all matrix factorisation methods are together and all naive approach methods are together.\n",
    "\n",
    "Most python cells, and most method sections, are introduced with a markdown section (such as this one) to quickly introduce what the python cell(s) are doing and on what methodology they are based.\n",
    "\n",
    "#### Experimentation\n",
    "In order to run the experiments, all python cells up to the last two (bottom two under the *experimentation* section) need to first be run. This is done in order to initialize all the utility methods and optimization methods. ***They need to be run from top to bottom.***\n",
    "\n",
    "The *final two cells* under the *experimentation* section are used for data ingesting from the MovieLens 1M dataset and then automatically running the 5 fold cross validation experimentation over *all* methods.\n",
    "\n",
    "Please note that running the full 5 fold cross validation run can be quite ***slow*** (especially UV matrix decomposition)! The individual approaches can be \"turned on\" and \"turned off\" by setting the following flags to either `True` or `False` respectively:\n",
    "\n",
    "`\n",
    "run_naive = True\n",
    "run_UV_decomp = True\n",
    "run_matrix_fac = True\n",
    "`\n",
    "\n",
    "#### Running the experiments\n",
    "In order to run the experiments and replicate our results, simply load in this Jupyter Notebook file (no additional libraries required) and run all cells. Commonly Notebook editors have a button *\"Run All\"* under a tab *\"cells\"*, this will load all the required cells and automatically start the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File loading\n",
    "The following two functions are used to read a file and convert the CSV contents *(:: delimited)* to a list of python dictionaries.\n",
    "\n",
    "```format_add``` is an utility function used to construct a dictionary based on the required format.  \n",
    "```build_file``` reads an input file and uses `format_add` to create the dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_add(format_list, input_data, target_data):\n",
    "    \"\"\"\n",
    "    Constructs a dictionary using input_data and \n",
    "    the format_list as the dictionary format and \n",
    "    appends the dictionary to the target data.\n",
    "    \"\"\"\n",
    "    \n",
    "    appender_dict = {}\n",
    "    \n",
    "    for count, item in enumerate(format_list):\n",
    "        try:\n",
    "            appender_dict.update({item: input_data[count]})\n",
    "        except IndexError:\n",
    "            appender_dict.update({item: None})\n",
    "            \n",
    "    target_data.append(appender_dict)\n",
    "\n",
    "def build_file(format_list, file_path, delimiter):\n",
    "    \"\"\"\n",
    "    Reads a file and converts the delimiter separated data \n",
    "    in the file, based on the format provided by format_list, \n",
    "    into a dictionary list.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    with open(file_path) as file:\n",
    "        print(f\"Unpacking: '{file_path}'\")\n",
    "    \n",
    "        for line in file:\n",
    "            stripped_line = line.strip().split(delimiter)\n",
    "            format_add(format_list, stripped_line, new_list)\n",
    "        \n",
    "    print(\"Unpacked succesfully\")\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to numpy\n",
    "The following functions are used to convert the input data into both a 2D numpy array and to calculate the means of the columns and rows of said array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def construct_M_array(row_size, column_size, data, make_nan=True):\n",
    "    \"\"\"\n",
    "    Convert a list of dictionary values in the form of \"data\" into\n",
    "    a 2D numpy array with row and column size being: \"row_size\", \"column_size\".\n",
    "    \"\"\"\n",
    "    M_array = np.zeros((row_size, column_size))\n",
    "\n",
    "    for item in data:\n",
    "        itv = list(item.values())\n",
    "        M_array[int(itv[0]) - 1, int(itv[1]) - 1] = float(itv[2])\n",
    "\n",
    "    if make_nan:\n",
    "        M_array = np.where(M_array == 0., np.NaN, M_array)\n",
    "        \n",
    "    return M_array\n",
    "\n",
    "def get_row_col_mean(data):\n",
    "    \"\"\"\n",
    "    Return two arrays of the row and column means of a given 2D numpy array.\n",
    "    \"\"\"\n",
    "    return np.nanmean(data, axis=1), np.nanmean(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics\n",
    "The following two functions are used to *(efficiÃ«ntly)* calculate both:\n",
    " - The **Root Mean Square Error** (`RSME_two_arrays`)\n",
    " - The **Mean Absolute Error** (`MAE_two_arrays`)  \n",
    " \n",
    "Between two (numpy) arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def RSME_two_arrays(arr_1, arr_2):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Square Error between two equally sized numpy arrays.\n",
    "    arr_1 is the prediction array.\n",
    "    arr_2 is the test array.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean(((arr_1 - arr_2) ** 2)))\n",
    "\n",
    "def MAE_two_arrays(arr_1, arr_2):\n",
    "    \"\"\"\n",
    "    Calculate the Mean absolute Error between two equally sized numpy arrays.\n",
    "    arr_1 is the prediction array.\n",
    "    arr_2 is the test array.\n",
    "    \"\"\"\n",
    "    return np.nanmean(np.absolute(arr_1 - arr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matrixes(ratingsMatrix, testing_array, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculate the root mean squared error and mean absolute error between two arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    RSME = RSME_two_arrays(ratingsMatrix, testing_array)\n",
    "    MAE = MAE_two_arrays(ratingsMatrix, testing_array)\n",
    "    \n",
    "    if verbose:\n",
    "        print(RSME_two_arrays(ratingsMatrix, testing_array))\n",
    "        print(MAE_two_arrays(ratingsMatrix, testing_array))\n",
    "    \n",
    "    return RSME, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive approaches\n",
    "Run linear regression on the user and item datasets to find the coefficients of both and the intercepts of both (alpha, beta and gamma respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def perform_linear_regression(user_ids_size, item_ids_size, R_user, R_item):\n",
    "    \"\"\"\n",
    "    Perform linear regression on average user rating and average item rating values.\n",
    "    \n",
    "    Returns the alpha, beta and gamma values, which are, \n",
    "    the user coefficient, the item coefficient and the average intercept respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    LR_1 = LinearRegression()\n",
    "    LR_2 = LinearRegression()\n",
    "\n",
    "    # Regress over average user rating values\n",
    "    user_ids_array = np.arange(1, user_ids_size, 1)\n",
    "\n",
    "    LR_1.fit(user_ids_array.reshape(-1,1), R_user)\n",
    "    alpha = LR_1.coef_\n",
    "\n",
    "    # Regress over average item rating values\n",
    "    item_ids_array = np.arange(1, item_ids_size, 1)\n",
    "\n",
    "    LR_2.fit(item_ids_array.reshape(-1,1), R_item)\n",
    "    beta = LR_2.coef_\n",
    "\n",
    "    # Set the intercept gamma value as the average of both linear regressions intercepts\n",
    "    gamma = (LR_1.intercept_ + LR_2.intercept_) / 2\n",
    "    \n",
    "    return alpha, beta, gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a calculated alpha, beta and gamma value, check the findings against the testset and calculate the RMSE and MAE of each of the 5 naive approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_approaches(alpha, beta, gamma, Rating_test, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculate the root mean squared error and mean absolute error of the\n",
    "    5 different naive approaches which are:\n",
    "        - global average rating prediction\n",
    "        - item average rating prediction\n",
    "        - user average rating prediction\n",
    "        - user item linear regression without gamma rating prediction\n",
    "        - user item linear regression with gamma rating prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    #Root mean squared error\n",
    "    RMSE_global = 0\n",
    "    RMSE_item = 0\n",
    "    RMSE_user = 0\n",
    "    RMSE_user_item = 0\n",
    "    RMSE_user_item_gamma = 0\n",
    "\n",
    "    #Mean absolute error\n",
    "    MAE_global = 0\n",
    "    MAE_item = 0\n",
    "    MAE_user = 0\n",
    "    MAE_user_item = 0\n",
    "    MAE_user_item_gamma = 0\n",
    "\n",
    "    # For every rating value in the original dataset, calculate the error values\n",
    "    for rating in Rating_test:\n",
    "        _global = int(rating['rating']) - int(R_global)\n",
    "        RMSE_global += (_global)**2\n",
    "        MAE_global += abs(_global) \n",
    "        \n",
    "        # Try since we are not sure the item is trained in the trainingsset\n",
    "        try:\n",
    "            _item = int(rating['rating']) - R_item[int(rating['mid']) - 1]  \n",
    "        except:\n",
    "            _item = int(int(rating['rating']) - int(R_global))\n",
    "\n",
    "        RMSE_item += (_item)**2\n",
    "        MAE_item += abs(_item)\n",
    "        \n",
    "        # Try since we are not sure the user is trained in the trainingsset\n",
    "        try:\n",
    "            _user = int(rating['rating']) - R_user[int(rating['uid'])  - 1]\n",
    "        except:\n",
    "            _user = int(rating['rating']) - int(R_global)\n",
    "\n",
    "        RMSE_user += (_user)**2\n",
    "        MAE_user += abs(_user)\n",
    "        \n",
    "        # Try since we are not sure the item and user are trained in the trainingsset\n",
    "        try:\n",
    "            _user_item = int(rating['rating']) - int((alpha*R_user[int(rating['uid'])  - 1] + beta*R_item[int(rating['mid'])  - 1]))\n",
    "        except:\n",
    "            _user_item = int(rating['rating']) - int(R_global)\n",
    "\n",
    "        RMSE_user_item += (_user_item)**2\n",
    "        MAE_user_item += abs(_user_item)\n",
    "        \n",
    "        # Try since we are not sure the item and user are trained in the trainingsset\n",
    "        try:\n",
    "            _user_item_gamma = int(rating['rating']) - int((alpha*R_user[int(rating['uid'])  - 1] + beta*R_item[int(rating['mid'])  - 1]) + gamma)\n",
    "        except:\n",
    "            _user_item_gamma += int(rating['rating']) - int(R_global)\n",
    "\n",
    "        RMSE_user_item_gamma += (_user_item_gamma)**2\n",
    "        MAE_user_item_gamma += abs(_user_item_gamma)\n",
    "\n",
    "\n",
    "    rating_test_len = len(Rating_test)\n",
    "    \n",
    "    # Make sure we generate the *MEAN* of the computed values\n",
    "    RMSE_global = np.sqrt(RMSE_global/rating_test_len)\n",
    "    RMSE_item = np.sqrt(RMSE_item/rating_test_len)\n",
    "    RMSE_user = np.sqrt(RMSE_user/rating_test_len)\n",
    "    RMSE_user_item = np.sqrt(RMSE_user_item/rating_test_len)\n",
    "    RMSE_user_item_gamma = np.sqrt(RMSE_user_item_gamma/rating_test_len)\n",
    "\n",
    "    MAE_global = MAE_global/rating_test_len\n",
    "    MAE_item = MAE_item/rating_test_len\n",
    "    MAE_user = MAE_user/rating_test_len\n",
    "    MAE_user_item = MAE_user_item/rating_test_len\n",
    "    MAE_user_item_gamma = MAE_user_item_gamma/rating_test_len\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"RMSE global average: {RMSE_global}\")\n",
    "        print(f\"RMSE item average: {RMSE_item}\")\n",
    "        print(f\"RMSE user average: {RMSE_user}\")\n",
    "        print(f\"RMSE Linear Regression User Item (A,B): {RMSE_user_item}\")\n",
    "        print(f\"RMSE Linear Regression User Item (A,B,Y): {RMSE_user_item_gamma}\\n\")\n",
    "\n",
    "        print(f\"MAE global average: {MAE_global}\")\n",
    "        print(f\"MAE item average: {MAE_item}\")\n",
    "        print(f\"MAE user average: {MAE_user}\")\n",
    "        print(f\"MAE Linear Regression User Item (A,B): {MAE_user_item}\")\n",
    "        print(f\"MAE Linear Regression User Item (A,B,Y): {MAE_user_item_gamma}\")\n",
    "    \n",
    "    return RMSE_global, RMSE_item, RMSE_user, RMSE_user_item, RMSE_user_item_gamma, MAE_global, MAE_item, MAE_user, MAE_user_item, MAE_user_item_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization section\n",
    "Implementation based on the algorithms described in the [gravity-Tikk.pdf paper](https://www.cs.uic.edu/~liub/KDD-cup-2007/proceedings/gravity-Tikk.pdf) and [Netflix Update: Try This at Home](https://sifter.org/~simon/journal/20061211.html) *(note that the primary algorithm is from the gravity-Tikk paper)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict rating with the help of the to train values for movie and value\n",
    "def predictRating(movie, user):\n",
    "    return (movieValue[movie] + userValue[user])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training method using the error rate, a learning rate and a K. The learning rate and K are random small numbers proposed by the [gravity-Tikk.pdf paper](https://www.cs.uic.edu/~liub/KDD-cup-2007/proceedings/gravity-Tikk.pdf).  The training method alters the userValue and movieValue elements to predict new and closer ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data using the error rate and the standard predictionRating method\n",
    "def train(movieValue, userValue, user, movie, rating, lrate=0.001, K=0.02):\n",
    "    err = rating - predictRating(movie, user)\n",
    "    \n",
    "    uv = userValue[user];    \n",
    "    userValue[user] += lrate * (2 * err * movieValue[movie] - K * userValue[user])\n",
    "    movieValue[movie] += lrate * (2 * err * uv - K * movieValue[movie])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used for training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_matrix_factorization(user_ids_size, item_ids_size, user_data, movie_data, Rating_train):\n",
    "    #Create new 2D array with 0.01 (random small value) as base value\n",
    "    ratingsMatrix = np.full((user_ids_size, item_ids_size), 0.01)\n",
    "\n",
    "    #Initialize user and movie values setting their base value as the global average (random approximation value)\n",
    "    userValue = np.full((user_ids_size, ), R_global)\n",
    "    movieValue = np.full((item_ids_size, ), R_global)\n",
    "\n",
    "    #Traing on training set (keep on training the matrix untill it converges in a Gradient Descent)\n",
    "    converge = False\n",
    "    while converge == False:\n",
    "        avg_err = 0\n",
    "        for rating in Rating_train: \n",
    "            avg_err += train(movieValue, userValue, int(rating['uid']) - 1, int(rating['mid']) - 1, int(rating['rating']))\n",
    "        avg_err = avg_err / len(Rating_train)\n",
    "        print(avg_err)\n",
    "        #0.001 is a random small value set to determine the matrix to keep changing a lot and theirfore to converge or not to converge \n",
    "        if abs(avg_err) < 0.001:\n",
    "            converge = True\n",
    "\n",
    "    #Fill remaining values based on the trainingsset\n",
    "    for user in user_data:\n",
    "        for movie in movie_data:\n",
    "            ratingsMatrix[int(user['uid']) - 1, int(movie['mid']) - 1] = (userValue[int(user['uid']) - 1] + movieValue[int(movie['mid']) - 1])/2\n",
    "\n",
    "    return ratingsMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UV Matrix Decomposition\n",
    "Implementation of the algorithm as described in [Section 9.4 of the MMDS textbook](http://infolab.stanford.edu/~ullman/mmds/ch9.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def replace_nans(arr):\n",
    "    \"\"\"\n",
    "    Replace all NaNs occuring in the input array \"arr\"\n",
    "    \n",
    "    NaNs are replaced by the column average of a NaN cell. \n",
    "    If the column is empty (only NaN values), set the column average to the global average.\n",
    "    \n",
    "    Returns a modified copy of \"arr\" with all nans replaced\n",
    "    \"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "        copy_arr = np.copy(arr)\n",
    "\n",
    "        col_mean = np.nanmean(copy_arr, axis=0)\n",
    "        mean = np.nanmean(copy_arr)\n",
    "\n",
    "        col_mean = np.nan_to_num(col_mean, nan=mean)\n",
    "\n",
    "        inds = np.where(np.isnan(copy_arr))\n",
    "\n",
    "        copy_arr[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "        return copy_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing U and V cells from the $UV=M$ matrix.\n",
    "\n",
    "The **U optimization** is based on:\n",
    "\n",
    "$u_{rs}=\\frac{\\Sigma_{j}v_{sj}(m_{rj}-\\Sigma_{k\\neq s}u_{rk}v_{kj})}{\\Sigma_{j}v_{sj}^2}$\n",
    "\n",
    "Where $r,s$ are *row* and *column* values.\n",
    "\n",
    "Where $\\Sigma_{j}$ is shorthand for the sum of $j$ such that $m_{rj}$ is nonblank.\n",
    "\n",
    "The **V optimization** is based on:\n",
    "\n",
    "$v_{rs}=\\frac{\\Sigma_{i}u_{ir}(m_{is}-\\Sigma_{k\\neq r}u_{ik}v_{ks})}{\\Sigma_{i}u_{ir}^2}$\n",
    "\n",
    "Where $r,s$ are *row* and *column* values.\n",
    "\n",
    "Where $\\Sigma_{i}$ is shorthand for the sum of $i$ such that $m_{is}$ is nonblank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_U_cell(r, s, dim, U_matrix, V_matrix, M_matrix):\n",
    "    \"\"\"\n",
    "    Optimize a single cell with row \"r\" and column \"s\" of the U_matrix.\n",
    "    \n",
    "    Optimization based on Section 9.4.4 of the MMDS textbook\n",
    "    \n",
    "    Returns the optimized value of cell U[r,s].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Upper part of the optimization sum\n",
    "    x_above = 0\n",
    "    \n",
    "    for j in range(M_matrix.shape[1]):\n",
    "        M_val = M_matrix[r,j]\n",
    "        \n",
    "        if np.isnan(M_val):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        U_el_V_el_sum = 0\n",
    "        \n",
    "        for k in range(dim):\n",
    "            if k == s:\n",
    "                continue\n",
    "            U_el_V_el_sum += U_matrix[r,k] * V_matrix[k,j]\n",
    "            \n",
    "        x_above += V_matrix[s,j] * (M_val - U_el_V_el_sum)\n",
    "        \n",
    "    # Lower part of the optimization sum\n",
    "    x_under = 0\n",
    "    \n",
    "    for j in range(M_matrix.shape[1]):\n",
    "        if np.isnan(M_matrix[r,j]):\n",
    "            continue\n",
    "            \n",
    "        x_under += V_matrix[s, j] ** 2\n",
    "    \n",
    "    return x_above / x_under if x_under != 0. else x_above\n",
    "\n",
    "def optimize_V_cell(r, s, dim, U_matrix, V_matrix, M_matrix):\n",
    "    \"\"\"\n",
    "    Optimize a single cell with row \"r\" and column \"s\" of the V_matrix.\n",
    "    \n",
    "    Optimization based on Section 9.4.4 of the MMDS textbook\n",
    "    \n",
    "    Returns the optimized value of cell V[r,s].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Upper part of the optimization sum\n",
    "    y_above = 0\n",
    "    \n",
    "    for i in range(M_matrix.shape[0]):\n",
    "        M_val = M_matrix[i,s]\n",
    "        \n",
    "        if np.isnan(M_val):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        U_el_V_el_sum = 0\n",
    "        \n",
    "        for k in range(dim):\n",
    "            if k == r:\n",
    "                continue\n",
    "            U_el_V_el_sum += U_matrix[i,k] * V_matrix[k,s]\n",
    "            \n",
    "        y_above += U_matrix[i,r] * (M_val - U_el_V_el_sum)\n",
    "        \n",
    "    # Lower part of the optimization sum\n",
    "    y_under = 0\n",
    "    \n",
    "    for i in range(M_matrix.shape[1]):\n",
    "        if np.isnan(M_matrix[i,s]):\n",
    "            continue\n",
    "            \n",
    "        y_under += U_matrix[i, r] ** 2\n",
    "    \n",
    "    return y_above / y_under if y_under != 0. else y_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the optimization in a round robin fashion. This method alternates between matrix U_d and V_d when optimizing a cell. The method of traversal is given by a following example:\n",
    "\n",
    "$\n",
    "U=\\begin{bmatrix}\n",
    "0 & 2 \\\\\n",
    "4 & 6 \\\\\n",
    "8 & 10\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "V=\\begin{bmatrix}\n",
    "1 & 3 & 5 & 7\\\\\n",
    "9 & 11 & 12 & 13\n",
    "\\end{bmatrix}\n",
    "$\n",
    "        \n",
    "Note that the figure in each of the cells of the two matrices indicates the traversing order. If one of the matrices is bigger than the other, it will finish the larger matrix in a sequential fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_opti_round_robin(U_d_matrix, V_d_matrix, M_matrix, dimensions):\n",
    "    \"\"\"\n",
    "    Run UV decomposition optimization in a \"round robin fashion\". Based on U_d_matrix and V_d_matrix.\n",
    "    \n",
    "    The round robin approach works as:\n",
    "    U = [[0, 2],\n",
    "        [4, 6],\n",
    "        [8, 10]]\n",
    "        \n",
    "    V = [[1, 3, 5, 7],\n",
    "        [9, 11, 12, 13]]\n",
    "        \n",
    "    The optimizer alternates between the cells in U and V. \n",
    "    Note that if one array is larger, the final cells in the array are no longer done\n",
    "    in a round robin fashion. (See example above, cells 11, 12 and 13 in V are done in a sequence).\n",
    "    \"\"\"\n",
    "    \n",
    "    r_U, c_U = 0, 0\n",
    "    r_V, c_V = 0, 0\n",
    "    \n",
    "    run = True\n",
    "    \n",
    "    while run:\n",
    "        run = False\n",
    "        \n",
    "        # Run U cell optimizer\n",
    "        if r_U < U_d_matrix.shape[0] and c_U < U_d_matrix.shape[1]:\n",
    "            U_d_matrix[r_U, c_U] = optimize_U_cell(r_U, c_U, dimensions, U_d_matrix, V_d_matrix, M_matrix)\n",
    "            run = True\n",
    "            \n",
    "            c_U += 1\n",
    "\n",
    "            if c_U >= U_d_matrix.shape[1]:\n",
    "                r_U += 1\n",
    "                c_U = 0\n",
    "            \n",
    "        # Run V cell optimizer\n",
    "        if r_V < V_d_matrix.shape[0] and c_V < V_d_matrix.shape[1]:\n",
    "            V_d_matrix[r_V, c_V] = optimize_V_cell(r_V, c_V, dimensions, U_d_matrix, V_d_matrix, M_matrix)\n",
    "            run = True\n",
    "            \n",
    "            c_V += 1\n",
    "\n",
    "            if c_U >= V_d_matrix.shape[1]:\n",
    "                r_V += 1\n",
    "                c_V = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_UV_array(U_d_matrix, V_d_matrix, M_array, dimensions, reference_RSME, max_rounds=5, improvement_threshold=1.0e-10):\n",
    "    \"\"\"\n",
    "    Run round robin fashion UV cell optimization until the optimization converges.\n",
    "    \n",
    "    The convergence is based on a theshold improvement value. If the error reduces less than the improvement_threshold,\n",
    "    the run is cut short. If the threshold value is set to \"False\", this metric is ignored and the run continues\n",
    "    until max_rounds is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    difference = None\n",
    "\n",
    "    for i in range(max_rounds):\n",
    "        print(f\"opti-cycle {i}\")\n",
    "        run_opti_round_robin(U_d_matrix, V_d_matrix, M_array, dimensions)\n",
    "\n",
    "        result = RSME_two_arrays(M_array, np.matmul(U_d_matrix, V_d_matrix))\n",
    "        \n",
    "        improvement = reference_RSME - result if difference is None else difference - result\n",
    "        print(f\"RSME result round {i}: {result}, this constitutes an improvement of: {reference_RSME - result} and a difference of {improvement}\")\n",
    "        \n",
    "        if improvement_threshold is not False and improvement < improvement_threshold:\n",
    "            print(\"Improvement threshold reached, optimization stopping\")\n",
    "            return\n",
    "        \n",
    "        difference = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_UV_matrix_decomposition(training_array, testing_array, dimensions=2, max_rounds=5):\n",
    "    \"\"\"\n",
    "    Perform UV matrix decomposition and return the prediction matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace all nan values with column averages\n",
    "    users_movies_array_no_nans = replace_nans(training_array)\n",
    "\n",
    "    # Normalize user movies array.\n",
    "    users_movies_array_norm = np.linalg.norm(users_movies_array_no_nans)\n",
    "    users_movies_array_pp = users_movies_array_no_nans / users_movies_array_norm\n",
    "    \n",
    "    # Ititialize users and movies d matrix with the mean of \n",
    "    # the normalized users_movies_array divided by the dimensions.\n",
    "    mean_users_movies_array = np.nanmean(users_movies_array_pp)\n",
    "    start_value = np.sqrt(mean_users_movies_array/dimensions)\n",
    "    users_d_matrix = np.full((users_movies_array_pp.shape[0], dimensions), start_value)\n",
    "    movies_d_matrix = np.full((dimensions, users_movies_array_pp.shape[1]), start_value)\n",
    "    \n",
    "    # Find the baseline\n",
    "    base_line = RSME_two_arrays(testing_array, np.matmul(users_d_matrix, movies_d_matrix) * users_movies_array_norm)\n",
    "\n",
    "    optimize_UV_array(users_d_matrix, movies_d_matrix, users_movies_array_pp, dimensions, base_line, max_rounds=max_rounds)\n",
    "\n",
    "    return np.matmul(users_d_matrix, movies_d_matrix) * users_movies_array_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingesting\n",
    "Below, the three input files are ingested and processed to be usable in python.\n",
    "\n",
    "```user_data``` is a list of dictionaries where each entry in the list corresponds one to one with the lines in the input file. The relevant keys can be found in the provided list parameter in ```build_file()```. ```movie_data``` and ```rating_data``` follow the same principles.\n",
    "\n",
    "Fetching ```user_data[0]``` returns an entire line. Please be aware: ```[id]``` and UIDs might not map 1 to 1! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking: './ml-1m/users.dat'\n",
      "Unpacked succesfully\n",
      "Unpacking: './ml-1m/movies.dat'\n",
      "Unpacked succesfully\n",
      "Unpacking: './ml-1m/ratings.dat'\n",
      "Unpacked succesfully\n"
     ]
    }
   ],
   "source": [
    "file_path_users = \"./ml-1m/users.dat\"\n",
    "file_path_movies = \"./ml-1m/movies.dat\"\n",
    "file_path_ratings = \"./ml-1m/ratings.dat\"\n",
    "\n",
    "user_data = build_file(\n",
    "    [\"uid\", \"gender\", \"age\", \"occupation\", \"zip-code\"],\n",
    "    file_path_users,\n",
    "    \"::\"\n",
    ")\n",
    "\n",
    "movie_data = build_file(\n",
    "    [\"mid\", \"title\", \"genre\"],\n",
    "    file_path_movies,\n",
    "    \"::\"\n",
    ")\n",
    "\n",
    "rating_data = build_file(\n",
    "    [\"uid\", \"mid\", \"rating\", \"timestamp\"],\n",
    "    file_path_ratings,\n",
    "    \"::\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments\n",
    "Rating data is split between a testing and training set.\n",
    "\n",
    "These datasets are converted into a 2D array where users are the rows, movies the columns, and the cells are the ratings.\n",
    "\n",
    "This is done over 5 folds to perform 5 cross fold validation. For every fold all experiments are run. At the end of all folds, the average RMSE and MAE are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -#- Fold 0 -#- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-c74362966e6a>:16: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(data, axis=1), np.nanmean(data, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Running Naive approaches --- \n",
      " --- Running UV decomposition approach --- \n",
      "opti-cycle 0\n",
      "RSME result round 0: 2.2308603648578905e-05, this constitutes an improvement of: 1.1614223862436044 and a difference of 1.1614223862436044\n",
      "opti-cycle 1\n",
      "RSME result round 1: 2.212815969051611e-05, this constitutes an improvement of: 1.1614225666875624 and a difference of 1.8044395806279522e-07\n",
      "opti-cycle 2\n",
      "RSME result round 2: 2.158788466271562e-05, this constitutes an improvement of: 1.1614231069625902 and a difference of 5.402750278004892e-07\n",
      "opti-cycle 3\n",
      "RSME result round 3: 2.1474996131615455e-05, this constitutes an improvement of: 1.1614232198511214 and a difference of 1.1288853110016526e-07\n",
      "opti-cycle 4\n",
      "RSME result round 4: 2.1373985899166813e-05, this constitutes an improvement of: 1.1614233208613538 and a difference of 1.010102324486414e-07\n",
      " --- Running matrix factorization approach --- \n",
      "-0.03881741483244614\n",
      "-0.028821624869946164\n",
      "-0.01862318071751677\n",
      "-0.012449001443680758\n",
      "-0.008251491015922978\n",
      "-0.005212451781761045\n",
      "-0.0029264678323018102\n",
      "-0.001159566634708338\n",
      "0.00023572276904692445\n",
      " -#- Fold 1 -#- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-c74362966e6a>:16: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(data, axis=1), np.nanmean(data, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Running Naive approaches --- \n",
      " --- Running UV decomposition approach --- \n",
      "opti-cycle 0\n",
      "RSME result round 0: 2.232740054534455e-05, this constitutes an improvement of: 1.1614548158198654 and a difference of 1.1614548158198654\n",
      "opti-cycle 1\n",
      "RSME result round 1: 2.2130894657405837e-05, this constitutes an improvement of: 1.1614550123257534 and a difference of 1.965058879387137e-07\n",
      "opti-cycle 2\n",
      "RSME result round 2: 2.1586389417722765e-05, this constitutes an improvement of: 1.161455556830993 and a difference of 5.445052396830716e-07\n",
      "opti-cycle 3\n",
      "RSME result round 3: 2.1474588052182823e-05, this constitutes an improvement of: 1.1614556686323585 and a difference of 1.1180136553994212e-07\n",
      "opti-cycle 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "min_rand_val = 0\n",
    "\n",
    "max_rand_val = 1000\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "run_naive = True\n",
    "run_UV_decomp = True\n",
    "run_matrix_fac = True\n",
    "\n",
    "### Run experiments ###\n",
    "\n",
    "#Root mean squared error\n",
    "N_RMSE_global = 0\n",
    "N_RMSE_item = 0\n",
    "N_RMSE_user = 0\n",
    "N_RMSE_user_item = 0\n",
    "N_RMSE_user_item_gamma = 0\n",
    "F_RMSE = 0\n",
    "UV_RMSE = 0\n",
    "\n",
    "#Mean absolute error\n",
    "N_MAE_global = 0\n",
    "N_MAE_item = 0\n",
    "N_MAE_user = 0\n",
    "N_MAE_user_item = 0\n",
    "N_MAE_user_item_gamma = 0\n",
    "F_MAE = 0\n",
    "UV_MAE = 0\n",
    "\n",
    "for i in range(num_folds):\n",
    "    print(f\" -#- Fold {i} -#- \")\n",
    "    \n",
    "    ### Data setup ###\n",
    "    Rating_train, Rating_test = train_test_split(rating_data, test_size=0.2, random_state=random.randint(min_rand_val, max_rand_val))\n",
    "\n",
    "    training_array = construct_M_array(int(user_data[-1]['uid']), int(movie_data[-1]['mid']), Rating_train)\n",
    "\n",
    "    testing_array = construct_M_array(int(user_data[-1]['uid']), int(movie_data[-1]['mid']), Rating_test)\n",
    "\n",
    "    #the global average rating \n",
    "    R_global = np.nanmean(training_array)\n",
    "\n",
    "    #the average rating per user & item \n",
    "    R_user, R_item = get_row_col_mean(training_array)\n",
    "\n",
    "    R_user = np.nan_to_num(R_user, nan=np.nanmean(R_user))\n",
    "\n",
    "    R_item = np.nan_to_num(R_item, nan=np.nanmean(R_item))\n",
    "    \n",
    "    if run_naive:\n",
    "        print(\" --- Running Naive approaches --- \")\n",
    "        alpha, beta, gamma = perform_linear_regression(int(user_data[-1]['uid']) + 1, int(movie_data[-1]['mid']) + 1, R_user, R_item)\n",
    "\n",
    "        RMSE_global, RMSE_item, RMSE_user, RMSE_user_item, RMSE_user_item_gamma, MAE_global, MAE_item, MAE_user, MAE_user_item, MAE_user_item_gamma = test_naive_approaches(alpha, beta, gamma, Rating_test, verbose=False)\n",
    "\n",
    "        N_RMSE_global += RMSE_global\n",
    "        N_RMSE_item += RMSE_item\n",
    "        N_RMSE_user += RMSE_user\n",
    "        N_RMSE_user_item += RMSE_user_item\n",
    "        N_RMSE_user_item_gamma += RMSE_user_item_gamma\n",
    "\n",
    "        N_MAE_global += MAE_global\n",
    "        N_MAE_item += MAE_item\n",
    "        N_MAE_user +=MAE_user\n",
    "        N_MAE_user_item += MAE_user_item\n",
    "        N_MAE_user_item_gamma += MAE_user_item_gamma\n",
    "    \n",
    "    if run_UV_decomp:\n",
    "        print(\" --- Running UV decomposition approach --- \")\n",
    "        UV_predict_array = run_UV_matrix_decomposition(training_array, testing_array)\n",
    "        RSME, MAE = test_matrixes(UV_predict_array, testing_array, verbose=False)\n",
    "\n",
    "        UV_RMSE += RSME\n",
    "        UV_MAE += MAE\n",
    "    \n",
    "    if run_matrix_fac:\n",
    "        print(\" --- Running matrix factorization approach --- \")\n",
    "        MF_predict_array = run_matrix_factorization(int(user_data[-1]['uid']), int(movie_data[-1]['mid']), user_data, movie_data, Rating_train)\n",
    "        RSME, MAE = test_matrixes(MF_predict_array, testing_array, verbose=False)\n",
    "\n",
    "        F_RMSE += RSME\n",
    "        F_MAE += MAE\n",
    "    \n",
    "print(\" #-#-# Results: #-#-# \")\n",
    "print(f\"The following results are the averages of the {num_folds} folds\\n\")\n",
    "\n",
    "print(f\"RMSE global average: {N_RMSE_global / num_folds}\")\n",
    "print(f\"RMSE item average: {N_RMSE_item / num_folds}\")\n",
    "print(f\"RMSE user average: {N_RMSE_user / num_folds}\")\n",
    "print(f\"RMSE Linear Regression User Item (A,B): {N_RMSE_user_item / num_folds}\")\n",
    "print(f\"RMSE Linear Regression User Item (A,B,Y): {N_RMSE_user_item_gamma / num_folds}\\n\")\n",
    "print(f\"RMSE UV decomposition: {UV_RMSE / num_folds}\\n\")\n",
    "print(f\"RMSE matrix factorization: {F_RMSE / num_folds}\\n\")\n",
    "\n",
    "\n",
    "print(f\"MAE global average: {N_MAE_global / num_folds}\")\n",
    "print(f\"MAE item average: {N_MAE_item / num_folds}\")\n",
    "print(f\"MAE user average: {N_MAE_user / num_folds}\")\n",
    "print(f\"MAE Linear Regression User Item (A,B): {N_MAE_user_item / num_folds}\")\n",
    "print(f\"MAE Linear Regression User Item (A,B,Y): {N_MAE_user_item_gamma / num_folds}\")\n",
    "print(f\"MAE UV decomposition: {UV_MAE / num_folds}\\n\")\n",
    "print(f\"MAE matrix factorization: {F_MAE / num_folds}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
