{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hey Luit, hier alvast een opzet van de opdracht. Ik zal per blokje kort even aangeven of het boeiend voor jou is.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is **niet** belangrijk voor jouw onderdelen, dit is alleen hier om het inladen van bestanden te fixen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_add(format_list, input_data, target_data):\n",
    "    ### Constructs a dictionary using input_data and \n",
    "    ### the format_list as the dictionary format and \n",
    "    ### appends the dictionary to the target data.\n",
    "    \n",
    "    appender_dict = {}\n",
    "    \n",
    "    for count, item in enumerate(format_list):\n",
    "        try:\n",
    "            appender_dict.update({item: input_data[count]})\n",
    "        except IndexError:\n",
    "            appender_dict.update({item: None})\n",
    "            \n",
    "    target_data.append(appender_dict)\n",
    "\n",
    "def build_file(format_list, file_path, delimiter):\n",
    "    ### Reads a file and converts the delimiter separated data \n",
    "    ### in the file, based on the format provided by format_list, \n",
    "    ### into a dictionary list.\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    with open(file_path) as file:\n",
    "        print(f\"Unpacking: '{file_path}'\")\n",
    "    \n",
    "        for line in file:\n",
    "            stripped_line = line.strip().split(delimiter)\n",
    "            format_add(format_list, stripped_line, new_list)\n",
    "        \n",
    "    print(\"Unpacked succesfully\")\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier staan de drie belangrijke datasets.\n",
    "\n",
    "```user_data``` is een lijst van dictionaries waar elke dict een regel is uit de oorspronkelijke data bestanden. De keys zie je in de lijst van ```build_file()```. ```movie_data```en ```rating_data``` hebben het zelfde princiepe.\n",
    "\n",
    "Als je ```user_data[0]``` gebruikt, krijg je dus een hele regel. Let op, UIDs en ```[id]``` zijn mogelijk niet 1 op 1! (zie ```find_on_key_and_value``` voor makkelijker zoeken naar gebruikers/movies/ratings/andere dingen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking: './ml-1m/users.dat'\n",
      "Unpacked succesfully\n",
      "Unpacking: './ml-1m/movies.dat'\n",
      "Unpacked succesfully\n",
      "Unpacking: './ml-1m/ratings.dat'\n",
      "Unpacked succesfully\n"
     ]
    }
   ],
   "source": [
    "file_path_users = \"./ml-1m/users.dat\"\n",
    "file_path_movies = \"./ml-1m/movies.dat\"\n",
    "file_path_ratings = \"./ml-1m/ratings.dat\"\n",
    "\n",
    "user_data = build_file(\n",
    "    [\"uid\", \"gender\", \"age\", \"occupation\", \"zip-code\"],\n",
    "    file_path_users,\n",
    "    \"::\"\n",
    ")\n",
    "\n",
    "movie_data = build_file(\n",
    "    [\"mid\", \"title\", \"genre\"],\n",
    "    file_path_movies,\n",
    "    \"::\"\n",
    ")\n",
    "\n",
    "rating_data = build_file(\n",
    "    [\"uid\", \"mid\", \"rating\", \"timestamp\"],\n",
    "    file_path_ratings,\n",
    "    \"::\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik dit om een entry te zoeken gebaseerd op een key (zoals *uid*, *gender*, *title*) en de verwachtte waarde. **Let op** dit retourneerd een lijst (kunnen dus meerdere entries zijn), maar als je maar 1 ding zoekt doe je gewoon: ```find_on_key_and_value(blah, blah, blah)[0]``` of ```find_on_key_and_value(blah, blah, blah)[:1]``` (als er niets gevonden is krijg je een lege lijst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_on_key_and_value(target_data, key, value):\n",
    "    ### Filter the data based on a key-value combination in the list of dictionaries.\n",
    "    return list(filter(lambda obj : obj[key] == value, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier een algemeen gemiddelde, niet zo spannend denk ik, maar misschien nodig bij de twee grotere methodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "\n",
    "# Calculate the mean over a comprehenced list based \n",
    "# on the rating fields in rating_data to get a global mean. \n",
    "all_rating_mean = mean([int(item[\"rating\"]) for item in rating_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier moet je vooral niet kijken naar wat de code is, want comprehension is lekker niet zo leesbaar, maar dit zoekt alle gemiddelden voor een bepaalde ```target_mean``` gebaseerd op een ```target_key```.\n",
    "\n",
    "Dus: ```bind_mean(rating_data, user_data, \"uid\", \"rating\", all_rating_mean)``` zoekt voor alle gebruikers (*uid*) de gemiddelde rating die die gebruiker heeft gegeven en maakt vervolgens een dictionary met daarin de gemiddelde van die gebruikers gekoppeld aan de uid van die gebruiker.\n",
    "\n",
    "Oh ja, **let op**, de dataset is nogal groot, dus let er op dat dit even kan duren voordat het klaar is (5 minuten ofzo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, isnan\n",
    "\n",
    "def bind_mean(bind_data_source, bind_data_target, target_key, target_mean, default=None):\n",
    "    ### Creates a dictionary of target_keys with their respective means. \n",
    "    ### If the target key does not exist in the source_data, then a default value will be set.\n",
    "    return {l_obj[target_key]: x if not isnan(x := mean([int(item[target_mean]) for item in filter(lambda _r : _r[target_key] == l_obj[target_key], bind_data_source)])) else default for l_obj in bind_data_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze stap duurt dus waarschijnlijk rond de 5 minuten, maar je hoeft dit maar één keer te doen gelukkig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a dictionary of user_ids with the corresponding means of ratings that a user has given. \n",
    "# If the user does not exist in the ratings file, the global average rating is filled in instead.\n",
    "user_rating_mean = bind_mean(rating_data, user_data, \"uid\", \"rating\", all_rating_mean)\n",
    "\n",
    "# Generate a dictionary of movie_ids with the corresponding means of ratings that a movie has received. \n",
    "# If the movie does not exist in the ratings file, the global average rating is filled in instead.\n",
    "movie_rating_mean = bind_mean(rating_data, movie_data, \"mid\", \"rating\", all_rating_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wat voorbeelden van wat je van de data en functies kunt verwachten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uid': '1', 'gender': 'F', 'age': '1', 'occupation': '10', 'zip-code': '48067'}\n",
      "[{'uid': '80', 'gender': 'M', 'age': '56', 'occupation': '1', 'zip-code': '49327'}]\n",
      "[{'uid': '1', 'mid': '1193', 'rating': '5', 'timestamp': '978300760'}, {'uid': '1', 'mid': '2355', 'rating': '5', 'timestamp': '978824291'}, {'uid': '1', 'mid': '1287', 'rating': '5', 'timestamp': '978302039'}]\n",
      "3.7131782945736433\n",
      "3.8787234042553194\n",
      "3.581564453029317\n"
     ]
    }
   ],
   "source": [
    "print(user_data[0]) # First line in user_data file\n",
    "print(find_on_key_and_value(user_data, \"uid\", \"80\")) # Line based on uid=80\n",
    "print(find_on_key_and_value(rating_data, \"rating\", \"5\")[:3]) # First three lines based on rating=5\n",
    "print(user_rating_mean[\"2\"]) # The average score of movies given by the user with uid=2\n",
    "print(movie_rating_mean[\"6\"]) # The average score of a movie mid=5\n",
    "print(all_rating_mean) # Average of all scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in een trainings- en testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Rating_train, Rating_test = train_test_split(rating_data, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier doen  we wat leuke testjes op de trainingsset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#the global average rating \n",
    "R_global = mean([int(item[\"rating\"]) for item in Rating_train])\n",
    "\n",
    "#the average rating per item \n",
    "R_item = bind_mean(Rating_train, movie_data, \"mid\", \"rating\", all_rating_mean)\n",
    "\n",
    "#the average rating per user \n",
    "R_user = bind_mean(Rating_train, user_data, \"uid\", \"rating\", all_rating_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00022844226836526982\n",
      "0.0011676279136467738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luit_\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\luit_\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\'\\nLR.fit(R_item.values.reshape(-1,1), movie_data[\"mid\"].values)\\nbeta = LR.score(R_item.values.reshape(-1,1), movie_data[\"mid\"].values)\\n\\n#an “optimal” linear combination of the two averages with gamma\\n\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "#an “optimal” linear combination of the two averages (per user and per item) without gamma\n",
    "LR = LinearRegression()\n",
    "\n",
    "#R_user\n",
    "R_user_array = np.array(list(R_user.values()))\n",
    "\n",
    "user_ids = []\n",
    "for data in user_data:\n",
    "    user_ids.append(data['uid'])\n",
    "\n",
    "user_ids_array = np.array(user_ids)\n",
    "\n",
    "LR.fit(R_user_array.reshape(-1,1), user_ids_array)\n",
    "alpha = LR.score(R_user_array.reshape(-1,1), user_ids_array)\n",
    "print(alpha)\n",
    "\n",
    "#R_item\n",
    "R_item_array = np.array(list(R_item.values()))\n",
    "\n",
    "item_ids = []\n",
    "for item in movie_data:\n",
    "    item_ids.append(item['mid'])\n",
    "\n",
    "item_ids_array = np.array(item_ids)\n",
    "\n",
    "LR.fit(R_item_array.reshape(-1,1), item_ids_array)\n",
    "beta = LR.score(R_item_array.reshape(-1,1), item_ids_array)\n",
    "print(beta)\n",
    "\n",
    "gamma = np.random.gamma(1, 1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultaten van de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root mean squared error\n",
    "RMSE_global = 0\n",
    "RMSE_item = 0\n",
    "RMSE_user = 0\n",
    "RMSE_user_item = 0\n",
    "RMSE_user_item_gamma = 0\n",
    "\n",
    "for rating in Rating_test:\n",
    "    RMSE_global += (int(rating['rating']) - int(R_global))**2    \n",
    "    \n",
    "    try:\n",
    "        RMSE_item += (int(rating['rating']) - R_item[str(rating['mid'])])**2\n",
    "    except:\n",
    "        RMSE_item += (int(rating['rating']) - int(R_global))**2\n",
    "        \n",
    "    try:\n",
    "        RMSE_user += (int(rating['rating']) - R_user[str(rating['uid'])])**2\n",
    "    except:\n",
    "        RMSE_user += (int(rating['rating']) - int(R_global))**2\n",
    "    \n",
    "    try:\n",
    "        RMSE_user_item += (int(rating['rating']) - int((alpha*R_user[str(rating['uid'])] + beta*R_item[str(rating['mid'])])))**2\n",
    "    except:\n",
    "        RMSE_user_item += (int(rating['rating']) - int(R_global))**2\n",
    "    \n",
    "    try:\n",
    "        RMSE_user_item_gamma += (int(rating['rating']) - int((alpha*R_user[str(rating['uid'])] + beta*R_item[str(rating['mid'])]) + gamma))**2\n",
    "    except:\n",
    "        RMSE_user_item_gamma += (int(rating['rating']) - int(R_global))**2\n",
    "            \n",
    "RMSE_global = RMSE_global/len(Rating_test)\n",
    "RMSE_item = RMSE_item/len(Rating_test)\n",
    "RMSE_user = RMSE_user/len(Rating_test)\n",
    "RMSE_user_item = RMSE_user_item/len(Rating_test)\n",
    "RMSE_user_item_gamma = RMSE_user_item_gamma/len(Rating_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean absolute error\n",
    "MAE_global = 0\n",
    "MAE_item = 0\n",
    "MAE_user = 0\n",
    "MAE_user_item = 0\n",
    "MAE_user_item_gamma = 0\n",
    "\n",
    "for rating in Rating_test:\n",
    "    MAE_global += abs(int(rating['rating']) - int(R_global))   \n",
    "    \n",
    "    try:\n",
    "        MAE_item += abs(int(rating['rating']) - R_item[str(rating['mid'])])\n",
    "    except:\n",
    "        MAE_item += abs(int(rating['rating']) - int(R_global))\n",
    "        \n",
    "    try:\n",
    "        MAE_user += abs(int(rating['rating']) - R_user[str(rating['uid'])])\n",
    "    except:\n",
    "        MAE_user += abs(int(rating['rating']) - int(R_global))\n",
    "    \n",
    "    try:\n",
    "        MAE_user_item += abs(int(rating['rating']) - int((alpha*R_user[str(rating['uid'])] + beta*R_item[str(rating['mid'])])))\n",
    "    except:\n",
    "        MAE_user_item += abs(int(rating['rating']) - int(R_global))\n",
    "    \n",
    "    try:\n",
    "        MAE_user_item_gamma += abs(int(rating['rating']) - int((alpha*R_user[str(rating['uid'])] + beta*R_item[str(rating['mid'])]) + gamma))\n",
    "    except:\n",
    "        MAE_user_item_gamma += abs(int(rating['rating']) - int(R_global))\n",
    "\n",
    "MAE_global = MAE_global/len(Rating_test)\n",
    "MAE_item = MAE_item/len(Rating_test)\n",
    "MAE_user = MAE_user/len(Rating_test)\n",
    "MAE_user_item = MAE_user_item/len(Rating_test)\n",
    "MAE_user_item_gamma = MAE_user_item_gamma/len(Rating_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printen van de resultaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5784215784215785\n",
      "1.0042911302371926\n",
      "1.0256179589493952\n",
      "14.03096903096903\n",
      "1.5784215784215785\n",
      "1.022977022977023\n",
      "0.8051858320604869\n",
      "0.8087778142448817\n",
      "3.5754245754245755\n",
      "1.022977022977023\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_global)\n",
    "print(RMSE_item)\n",
    "print(RMSE_user)\n",
    "print(RMSE_user_item)\n",
    "print(RMSE_user_item_gamma)\n",
    "\n",
    "print(MAE_global)\n",
    "print(MAE_item)\n",
    "print(MAE_user)\n",
    "print(MAE_user_item)\n",
    "print(MAE_user_item_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
